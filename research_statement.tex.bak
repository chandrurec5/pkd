%\documentclass[oneside,8pt,onecolumn,openright]{IIScthesisPSnPDF}
aaaga
\documentclass[onecolumn,12pt]{IEEEtran}
\input{pack.tex}
%\usepackage[numbers]{natbib}
\title{Algorithms for Planning and Decision making Under Uncertainty}
\author{}
\date{}
\begin{document}
%\Huge
%\begin{center}
%Panel of Experts
%\end{center}
\maketitle
%\input{abstract}
\section{Introduction}
Real world is often uncertain, staring from the time taken one waits for a bus to the amount of rainfall in a given year. Decision making and planning in the face of such uncertainty is hence crucial if we are interested in designing practical systems with good performance. Several important problems arising in domains such as urban development (traffic signal control, planning of road networks, facility), health care (mobile health, drug deployment during epidemic outbreak), computation (cloud computing, optimal caching), communication (forwarding in sensor networks), artificial intelligence (automated driving, terrain exploring robots), e-commerce (electronic auctions) and energy sector (smart grids) are planning and decision making problems. Further, in a host of scenarios (especially involving public policy) multiple parties are involved and decision making has to balance their self-interest and overall benefit for the community. Planning needs to take into account various challenges such as system complexity, lack of knowledge about the nature of uncertainty, resource and budget constraints. In order to address these challenges it is important to formalize them mathematically. The aim of the research is make use of mathematical tools to develop models, analysis and algorithms for planning under uncertainty.\par
\section{Objectives}
Recent times have seen the convergence of statistic, applied mathematics and computer science to give rise to an exciting field called Machine Learning. The rampant development of sensor technologies has resulted in large amounts of real-time data. The objectives of machine learning include modelling, analysis optimization and control via optimal decision making. 
%One of the major goals of machine learning is to develop algorithms that learn from vast data to solve the decision making problem in real-time. 
The Big Data Initiative~\textbf{http://dst.gov.in/big-data-initiative-1} by the government has recognized the importance of the use of machine learning methods towards decision making by declaring in its agenda that\\
\emph{ ``extracting useful knowledge for decision making purposes from these massive, large-scale data \ldots data-driven approaches, in biology, medicine, public policy, social sciences, and humanities, can replace the traditional hypothesis-driven research in science."
}\\
The objective of my research is to contribute to the big data initiative by developing models, analysis and algorithms for planning and decision making problems arising in the domains of urban planning, health care, sensor networks and human computation. The rest of the section gives a brief description of the rich variety of planning problems occurring in these domains.\par
\textbf{Urban Planning} We now look at how machine learning, estimation, optimization and control can address interesting problems in public transportation, facility development and resource distribution. Let us first consider the example of public transportation. Sensors attached to vehicles and those present in the smart devices carried by the commuters enable us to estimate traffic. Using this data, we can control the traffic lights appropriately and synchronize the road/rail timings thereby reducing commuter congestion. Since the data is real time, it is possible to redirect commuters and reduce the congestion in case of a jam. Further, the data thus obtained also reveal the frequently used routes thus enabling us to plan for new facilities and infrastructure. Also, by making use of appropriate optimization tools a phased allocation of budget for new infrastructures can be charted. Similarly, it is possible to measure the demand and usage of power/water by various facilities such as housing units, hospitals and industries. This data can be used to regulate the and control distribution of these resources thus avoiding outages.\par
\textbf{Sensor Networks:} 
Sensors serves as an important backbone of real-time data-driven decision making. In general, most sensors are mobile and as hence they turn out to be battery operated as well. Recent times have seen development of energy harvesting sensors that convert solar power or even vibrations into energy. Since the sensors are not connected to a regular source of power it becomes important to be spend as less battery power as possible. As a result energy efficient transmission policies has attracted attention in recent times \cite{eh,sw}. This can be achieved by forming a network of sensors with one centralized controller that collates information from other nodes, and the center also has control over the \emph{sleep-wake} schedules of all the other nodes. The aim here is to come up with a policy that keeps the minimum number of sensors awake per unit time while meeting the communication objective.\par
\textbf{Health Care:} Optimal strategies for clinical trial design has been known for a long time \cite{clinical,clinical1}. An interesting recent advancement is to use data-driven decision making in the domain of Health care. In particular, exploiting patient specific data (history, congenital defects etc) to decide the remedy/drug-dosage to be administered from time to time is a challenging problem  \cite{mH1}. Another potential challenge is to use mobile devices for patient monitoring and for preventive interventions (alerting patients on the intake of medicine, therapy and rest)  \cite{mH2}. The algorithms have to be robust in that they have to factor the \emph{risk} associated with wrong treatments.\par
\textbf{Human Computing:} Crowdsourcing (crowd) is a new mode of organizing work in multiple groups of smaller chunks of tasks and outsourcing them to a distributed and large group of people in the form of an open call. Recently, crowd sourcing has become a major pool for human intelligence tasks (HITs) such as image labeling, form digitization, natural language processing, machine translation evaluation and user surveys. Human computing is important on two accounts (i) it is a major source for annotating data sets via human to be used for machine learning and (ii) it provides a sizeable amount of income for citizens willing to devote their free time. The challenge is to come up with efficient policies for pricing the tasks \cite{rp,mywork}, allocating them to crowd workers to ensure timely completion.\par
\begin{comment}
Task starvation leads to huge variation in the completion times of the tasks posted on to the crowd. This is an issue for frequent requesters desiring predictability in the completion times of tasks specified in terms of percentage of tasks completed within a stipulated amount of time. An important task attribute that affects the completion time of a task is its price. However, a pricing policy that does not take the dynamics of the crowd into account might fail to achieve the desired predictability in completion times. Here, we make use of the MDP framework to compute a pricing policy that achieves predictable completion times in simulations as well as real world experiments. 
\end{comment}
\section{Tools and Techniques}
We have to address certain important challegens while undertaking data-driven approaches to decision making and planning. In what follows we describe some of the challenges and the specific tools to tackle them.
\textbf{Modelling}: Identifying the right mathematical model is important and is the first step. A large number of sequential decision making problems occurring in practice can be modelled as \emph{Markov Decision Processes} (MDPs) \cite{BertB}. MDPs can be used to model  traffic signalling, sensor networks, interventional health care and the problems in crowd sourcing. \emph{Constrained and Risk} sensitive formulation of the MDP can be applied to domains such as urban planning and health care respectively. The class of discrete event systems where elementary components interact via `synchronization' are called \emph{Stochastic $\max-$ Plus (SMPL) Systems} \cite{smpl}. SMPL framework will be used to analyze the problem of scheduling road and rail network at tandem.\par
\textbf{Handling complex systems:} Approximate Dynamic Programming (ADP) algorithms \cite{powell} tackle the complexity of systems (i.e, of large number of states) by cleverly combining approximate representations and mathematical optimization. Further, tools such as stochastic approximation can be used to reduce the number of computations in the case of systems with large number of dimensions. The techniques enable us to build scalable algorithms.
\par
\textbf{Presence of multiple self-interested parties:} Game Theory and Mechanism Design \cite{gtmd} are natural frameworks to address decision problems involving multiple self-interested parties. Analyzing the Nash Equilibrium of a game offers insights on the kind of outcomes expected when self-interested parties are making the decision. A classical case is the \emph{Baress's Paradox} \cite{braess} which explains why building an additional road does not always improve congestion, a fact which has also been verified in practice \cite{}. Mechanism Design is a useful tool to address questions related various critical aspects to multi-party decision problems such as fairness and efficiency in allocating the resources, budget balance, individual rationale of the parties involved and truthful behavior.\par
\textbf{Sample Complexity:} The \emph{multi-arm-bandit} problem \cite{auer} is an example of trade off between exploration (trying out the arms to find the best arm) and exploitation (playing the arm currently known to be the best). Bandit theory addresses the question of optimal sampling and at the same time with lesser compromise in performance, and is helpful in scenarios where samples need to be collected in an efficient way. Several variants of the problems include linear bandits, convex bandits, contextual bandits, bandits with complex or partial feedback have been considered in literature to model various scenarios. We believe the research problems considered in this proposal will give rise to more interesting variants of bandit problems.\par
\textbf{Real Time interaction:} Reinforcement Learning (RL) algorithms \cite{sutton} learn the optimal decision via feedback obtained by directly interacting with the system. Thus ADP and RL algorithms will be deployed when the system is complicated (i.e., road network with hundreds of junctions) and the exact model information is not present (crowd behavior is chaotic). \emph{Multi-agent} RL algorithms can be used together with techniques from spectral graph theory to exploit the network topology to come up with decentralized policies for energy harvesting sensors.\par
\begin{comment}
\begin{table}
\begin{tabular}{cc}

\end{tabular}
\end{table}
\end{comment}
\section{Significance}
The problem domains mentioned in this proposal have been studied in the past as well. However, what is interesting and has to been seen via further study is the impact of sophisticated tools such as machine learning, game theory and bandit theory in deriving robust, scalable and real-time algorithms for these domains. In addition, these newer domains are expected to goad us to develop newer theoretical frameworks and also look at some of the well known theoretical challenges under new light.
\section{Long-Term Prospects}
The models, analysis and algorithms developed in this research will also naturally extend to ecology (modelling prey/predator characteristics, migratory behavior, afforestation planning) and disaster management (modelling and planning of resources under calamity). The research in road traffic, sensor network and city planning will eventually lead to building of smarter cities. A long-term goal is evolve public policies more in the lines of projects such as PATH, TOPL (http://www.path.berkeley.edu/).
\small
\bibliographystyle{plain}
\bibliography{ref}

\end{document}




